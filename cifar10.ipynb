{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import argparse\n",
    "from models.resnet import resnet50\n",
    "from datasets import load_cifar10, load_cifar100, load_caltech_101\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import os\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "from foolbox.attacks import LinfPGD, L2PGD, L2BasicIterativeAttack, LinfBasicIterativeAttack, L2CarliniWagnerAttack\n",
    "from foolbox import PyTorchModel\n",
    "from tqdm import tqdm\n",
    "from sigmoid_method import exp as sigmoid_exp\n",
    "from combine_method import exp as combine_exp\n",
    "from utils import setup_seed,AverageMeter\n",
    "setup_seed(3407)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, test_dataloader, data_min, data_max = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack = LinfPGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_model = PyTorchModel(model, bounds=(data_min-1e-8, data_max+1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caculate_total(model, x, delta_x, y, steps=5, alpha=0.0025, lambda_r=0.01, op=\"add\"):\n",
    "    total = None\n",
    "    delta_x = delta_x.clone()\n",
    "    delta_x = torch.nn.Parameter(data=delta_x)\n",
    "    loss_func = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "    x.requires_grad_(False)\n",
    "    delta_x.requires_grad_(True)\n",
    "    model.zero_grad()\n",
    "    for _ in range(steps):\n",
    "        outputs = model(x+delta_x)\n",
    "        model.zero_grad()\n",
    "        loss = loss_func(outputs, y)\n",
    "        regularization_loss = torch.norm(delta_x)\n",
    "        if op == \"minus\":\n",
    "            loss = loss + lambda_r * regularization_loss\n",
    "            loss.backward(retain_graph=True)\n",
    "            grad = delta_x.grad\n",
    "            delta_x = delta_x - alpha * torch.sign(grad)\n",
    "        elif op == \"add\":\n",
    "            loss = loss - lambda_r * regularization_loss\n",
    "            loss.backward(retain_graph=True)\n",
    "            grad = delta_x.grad\n",
    "            delta_x = delta_x + alpha * torch.sign(grad)\n",
    "        delta_x = delta_x.detach().requires_grad_(True)\n",
    "        if total == None:\n",
    "            total = ((alpha * torch.sign(grad)) * grad).detach()\n",
    "        else:\n",
    "            total += ((alpha * torch.sign(grad)) * grad).detach()\n",
    "        model.zero_grad()\n",
    "    return total\n",
    "\n",
    "\n",
    "def caculate_combine(total, delta, use_total=True, use_delta=True):\n",
    "    if use_total and use_delta:\n",
    "        combine = torch.abs(torch.abs(total) * delta)\n",
    "    elif use_total:\n",
    "        combine = torch.abs(total)\n",
    "    elif use_delta:  # taylor\n",
    "        combine = torch.abs(delta)\n",
    "    combine = combine.unsqueeze(0).cpu().detach().numpy()\n",
    "    combine_flatten = combine.flatten()\n",
    "    return combine, combine_flatten\n",
    "\n",
    "\n",
    "def get_result(model, x, pos, combine, combine_flatten, delta):\n",
    "    threshold = np.sort(combine_flatten)[pos]\n",
    "    delta_ = delta.clone()\n",
    "    delta_[combine < threshold] = 0\n",
    "    result = model(x+delta_).argmax(-1)\n",
    "    return result, torch.norm(delta_).item(), delta_\n",
    "\n",
    "\n",
    "def binary_search(model, x, delta, y, r, combine, combine_flatten, search_times=10):\n",
    "    l = 0\n",
    "    r = r\n",
    "    pos = int((l + r) / 2)\n",
    "    y_label = y.argmax(-1)\n",
    "    for _ in range(search_times):\n",
    "        if l == r:\n",
    "            break\n",
    "        result, norm_delta, delta_ = get_result(\n",
    "            model, x, pos, combine, combine_flatten, delta)\n",
    "        if result == y_label:\n",
    "            l = pos\n",
    "            pos = int((pos + r) / 2)\n",
    "            flag = pos\n",
    "            flag_norm = norm_delta\n",
    "            flag_delta = delta_\n",
    "        else:\n",
    "            r = pos\n",
    "            pos = int((pos + l) / 2)\n",
    "    return flag, flag_norm, flag_delta\n",
    "\n",
    "\n",
    "def exp(model, x, delta_x, y, add_steps=5, minus_steps=0, alpha=0.0025, lambda_r=0.01, method=\"total*delta\"):\n",
    "    if add_steps != 0:\n",
    "        total_add = caculate_total(\n",
    "            model, x.unsqueeze(0), delta_x.unsqueeze(0), y.argmax(-1).unsqueeze(0), steps=add_steps, op=\"add\", alpha=alpha, lambda_r=lambda_r)\n",
    "    if minus_steps != 0:\n",
    "        total_minus = caculate_total(\n",
    "            model, x.unsqueeze(0), delta_x.unsqueeze(0), y.argmax(-1).unsqueeze(0), steps=minus_steps, op=\"minus\", alpha=alpha, lambda_r=lambda_r)\n",
    "    if add_steps != 0 and minus_steps != 0:\n",
    "        total = total_add + total_minus\n",
    "    elif add_steps != 0:\n",
    "        total = total_add\n",
    "    elif minus_steps != 0:\n",
    "        total = total_minus\n",
    "    delta_x = delta_x.unsqueeze(0)\n",
    "    if method == \"total*delta\":\n",
    "        combine, combine_flatten = caculate_combine(\n",
    "            total, delta_x, use_total=True, use_delta=True)\n",
    "    elif method == \"total\":\n",
    "        combine, combine_flatten = caculate_combine(\n",
    "            total, delta_x, use_total=True, use_delta=False)\n",
    "    elif method == \"taylor\":\n",
    "        combine, combine_flatten = caculate_combine(\n",
    "            total, delta_x, use_total=False, use_delta=True)\n",
    "    _, flag_norm, _ = binary_search(model, x.unsqueeze(0), delta_x, y, len(\n",
    "        combine_flatten) - 1, combine, combine_flatten, search_times=10)\n",
    "    return flag_norm\n",
    "\n",
    "def print_adv_pred_bar(adv_pred):\n",
    "    plt.bar(list(range(10)), nn.Softmax()(adv_pred[0]).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:09<00:00,  2.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5233, device='cuda:0')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "total = 1\n",
    "pbar = tqdm(total=total)\n",
    "avg = AverageMeter()\n",
    "for x, label in test_dataloader:\n",
    "    x, label = x.to(device), label.to(device)\n",
    "    pred = model(x)\n",
    "    correct = pred.argmax(-1) == label\n",
    "    x = x[correct]\n",
    "    label = label[correct]\n",
    "    _, adv_data, success = attack(pt_model, x, label, epsilons=0.5)\n",
    "    adv_pred = model(adv_data)\n",
    "    success_x = x[success]\n",
    "    success_adv_data = adv_data[success]\n",
    "    success_label = label[success]\n",
    "    # print('success_adv_data', success_adv_data.shape)\n",
    "    success_y = adv_pred[success]\n",
    "    print_adv_pred_bar(pred[correct])\n",
    "    print_adv_pred_bar(adv_pred)\n",
    "    for x, label, delta_x, y in zip(success_x, success_label, success_adv_data-success_x, success_y):\n",
    "        delta_x_norm = torch.norm(delta_x)\n",
    "        try:\n",
    "            norm = exp(x=x, delta_x=delta_x, y=y, model=model, add_steps=5, minus_steps=0, alpha=0.1, lambda_r=0.01, method=\"total*delta\")\n",
    "            avg.calculate(norm, delta_x_norm)\n",
    "        except:\n",
    "            continue\n",
    "        pbar.update(1)\n",
    "        count += 1\n",
    "        if count == total:\n",
    "            break\n",
    "    if count == total:\n",
    "        break\n",
    "print(avg.avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
